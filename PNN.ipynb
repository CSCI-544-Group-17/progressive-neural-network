{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3V6dJxixxrln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450d546c-fe76-4161-c86f-b3ef2d715ff5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Incrementally and Evaluate\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "95WfT7ekO8pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "class InitialColumnProgNN(nn.Module):\n",
        "    def __init__(self, topology, activations):\n",
        "        super(InitialColumnProgNN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(topology) - 1):\n",
        "            self.layers.append(nn.Linear(topology[i], topology[i+1]))\n",
        "        self.activations = activations\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            # removinf softmax from last layer because of crossentropyloss function - vishal\n",
        "            if i != len(self.activations):\n",
        "              x = self.activations[i](x)\n",
        "        return x\n",
        "\n",
        "class ExtensibleColumnProgNN(nn.Module):\n",
        "    def __init__(self, topology, activations, prev_columns):\n",
        "        super(ExtensibleColumnProgNN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.lateral_connections = nn.ModuleList()\n",
        "        for i in range(len(topology) - 1):\n",
        "            self.layers.append(nn.Linear(topology[i], topology[i+1]))\n",
        "            if i > 0:\n",
        "                lateral = [nn.Linear(prev_column.layers[i-1].out_features, topology[i+1], bias=False) for prev_column in prev_columns]\n",
        "                self.lateral_connections.append(nn.ModuleList(lateral))\n",
        "        self.activations = activations\n",
        "        self.prev_columns = prev_columns\n",
        "\n",
        "    def forward(self, x):\n",
        "        prev_hs = [[[] for j in range(len(prev_col.layers))] for prev_col in self.prev_columns]\n",
        "\n",
        "        for j in range(len(self.prev_columns)):\n",
        "            x_copy = x.clone()\n",
        "            for i, col_layer in enumerate(self.prev_columns[j].layers):\n",
        "                x_copy = col_layer(x_copy)\n",
        "                # removinf softmax from last layer because of crossentropyloss function - vishal\n",
        "                if i != len(self.prev_columns[j].activations):\n",
        "                  x_copy = self.prev_columns[j].activations[i](x_copy)\n",
        "                prev_hs[j][i] = x_copy.clone()\n",
        "\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(x)\n",
        "            if i > 0:\n",
        "                for j, lateral in enumerate(self.lateral_connections[i-1]):\n",
        "                    x += lateral(prev_hs[j][i - 1])\n",
        "            # removinf softmax from last layer because of crossentropyloss function - vishal\n",
        "            if i != len(self.activations):\n",
        "              x = self.activations[i](x)\n",
        "        return x\n",
        "\n",
        "#todo: add training batch size later\n",
        "def train_column(column, data, target, epochs=50, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(column.parameters(), lr=lr)\n",
        "    # saved h_values for training lateral connections\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        output = column(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch%10 == 0:\n",
        "          print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n",
        "\n",
        "def test_column(column, embeddings, labels):\n",
        "    column.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        test_outputs = column(embeddings)\n",
        "        _, predicted = torch.max(test_outputs, 1)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(labels, predicted)\n",
        "\n",
        "        # Calculate F1 score\n",
        "        f1 = f1_score(labels, predicted)\n",
        "\n",
        "        # Calculate precision\n",
        "        precision = precision_score(labels, predicted)\n",
        "\n",
        "        # Calculate recall\n",
        "        recall = recall_score(labels, predicted)\n",
        "\n",
        "        print(\"Accuracy: {:.2f}\".format(accuracy))\n",
        "        print(\"F1 Score: {:.2f}\".format(f1))\n",
        "        print(\"Precision: {:.2f}\".format(precision))\n",
        "        print(\"Recall: {:.2f}\".format(recall))\n",
        "\n",
        "class PNN():\n",
        "    def __init__(self):\n",
        "        self.num_classes = 1\n",
        "\n",
        "        self.topology = [256, 100, 64, 25, 2]\n",
        "        self.activations = [F.relu, F.relu, F.relu]\n",
        "\n",
        "        # Instantiate the first module\n",
        "        self.subnetworks = [InitialColumnProgNN(self.topology, self.activations)]\n",
        "\n",
        "        # # Define the layer on top\n",
        "        # self.output_layer = nn.Linear(in_features=num_classes*2, out_features=num_classes)\n",
        "\n",
        "    def add_network(self):\n",
        "        self.num_classes += 1\n",
        "        self.subnetworks.append(ExtensibleColumnProgNN(self.topology, self.activations, self.subnetworks))\n",
        "\n",
        "    def train(self, subnetwork, embeddings, labels):\n",
        "        for i in range(self.num_classes):\n",
        "            if i == subnetwork:\n",
        "                # Unfreeze the parameters of the modules\n",
        "                for param in self.subnetworks[i].parameters():\n",
        "                    param.requires_grad = True\n",
        "            else:\n",
        "                # Freeze the parameters of the modules\n",
        "                for param in self.subnetworks[i].parameters():\n",
        "                    param.requires_grad = False\n",
        "        # Train the relevant PNN\n",
        "        train_column(self.subnetworks[subnetwork], embeddings, labels, epochs=100)\n",
        "\n",
        "        #Unfreeze all parameters\n",
        "        for i in range(self.num_classes):\n",
        "            for param in self.subnetworks[i].parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "    def test(self, embeddings, labels):\n",
        "        for i in range(self.num_classes):\n",
        "            print('\\nResults for class', i, '-')\n",
        "            test_column(self.subnetworks[i], embeddings, labels[i])\n",
        "\n",
        "        #  # Concatenate the outputs along the feature dimension (dimension 1)\n",
        "        # combined_output = torch.cat((output1, output2), dim=1)\n",
        "\n",
        "        # # Apply additional layer\n",
        "        # final_output = self.output_layer(combined_output)\n",
        "\n",
        "\n",
        "model = PNN()\n",
        "\n",
        "# train_column(model, embeddings0, labels0, epochs=50)"
      ],
      "metadata": {
        "id": "wgLE9b8ndwSY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.subnetworks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQD45hHaiTAe",
        "outputId": "e2b42e40-c7f0-4e07-9799-8cca24ef816f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[InitialColumnProgNN(\n",
              "   (layers): ModuleList(\n",
              "     (0): Linear(in_features=256, out_features=100, bias=True)\n",
              "     (1): Linear(in_features=100, out_features=64, bias=True)\n",
              "     (2): Linear(in_features=64, out_features=25, bias=True)\n",
              "     (3): Linear(in_features=25, out_features=2, bias=True)\n",
              "   )\n",
              " )]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "F-c08R5cjI8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/train_embeddings/dos_train_file_{i}.json', 'r') as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            embeddings.append(data['embeddings'][0])\n",
        "            labels.append(data['label'])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.train(0, embeddings=embeddings0, labels=labels0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQNHp2iy-oSG",
        "outputId": "ac78d28c-64c1-44d1-b411-898e708c8d2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4437, 256])\n",
            "torch.Size([4437])\n",
            "Epoch 1/100, Loss: 0.697877824306488\n",
            "Epoch 11/100, Loss: 0.6894388794898987\n",
            "Epoch 21/100, Loss: 0.6719402074813843\n",
            "Epoch 31/100, Loss: 0.6458081007003784\n",
            "Epoch 41/100, Loss: 0.6175787448883057\n",
            "Epoch 51/100, Loss: 0.5892585515975952\n",
            "Epoch 61/100, Loss: 0.5704184770584106\n",
            "Epoch 71/100, Loss: 0.5558143854141235\n",
            "Epoch 81/100, Loss: 0.5424866676330566\n",
            "Epoch 91/100, Loss: 0.5280255079269409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/dos_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([data['label']])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.test(embeddings0, labels0.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sraZqUdP4HY",
        "outputId": "efab6e44-8940-486d-c491-5953fc6f6287"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1109, 256])\n",
            "torch.Size([1109, 1])\n",
            "\n",
            "Results for class 0 -\n",
            "Accuracy: 0.72\n",
            "F1 Score: 0.72\n",
            "Precision: 0.74\n",
            "Recall: 0.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "XSYYXX6JkN--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/train_embeddings/+info_train_file_{i}.json', 'r') as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            embeddings.append(data['embeddings'][0])\n",
        "            labels.append(data['label'])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.add_network()\n",
        "model.train(1, embeddings=embeddings0, labels=labels0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0Zji3jmQank",
        "outputId": "e35e25cf-534e-4308-84dd-1d0d4b868af7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([984, 256])\n",
            "torch.Size([984])\n",
            "Epoch 1/100, Loss: 0.7490859627723694\n",
            "Epoch 11/100, Loss: 0.6737428903579712\n",
            "Epoch 21/100, Loss: 0.6307698488235474\n",
            "Epoch 31/100, Loss: 0.5876051783561707\n",
            "Epoch 41/100, Loss: 0.5408448576927185\n",
            "Epoch 51/100, Loss: 0.48283374309539795\n",
            "Epoch 61/100, Loss: 0.4343494772911072\n",
            "Epoch 71/100, Loss: 0.39462095499038696\n",
            "Epoch 81/100, Loss: 0.3554893732070923\n",
            "Epoch 91/100, Loss: 0.3147546648979187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/dos_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([data['label'], 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/+info_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, data['label']])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.test(embeddings0, labels0.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WX1WVq8uoXV",
        "outputId": "9baefa3d-5b04-4e2d-92c1-128041f735e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1355, 256])\n",
            "torch.Size([1355, 2])\n",
            "\n",
            "Results for class 0 -\n",
            "Accuracy: 0.68\n",
            "F1 Score: 0.70\n",
            "Precision: 0.78\n",
            "Recall: 0.64\n",
            "\n",
            "Results for class 1 -\n",
            "Accuracy: 0.45\n",
            "F1 Score: 0.59\n",
            "Precision: 0.92\n",
            "Recall: 0.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3"
      ],
      "metadata": {
        "id": "Rh7l0G99o7fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/train_embeddings/bypass_train_file_{i}.json', 'r') as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            embeddings.append(data['embeddings'][0])\n",
        "            labels.append(data['label'])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.add_network()\n",
        "model.train(2, embeddings=embeddings0, labels=labels0)\n",
        "\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/dos_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([data['label'], 1, 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/+info_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, data['label'], 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/bypass_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, 1, data['label']])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.test(embeddings0, labels0.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63VFkWjJOdx6",
        "outputId": "0714045e-6239-48fd-879e-5f01e546d795"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([709, 256])\n",
            "torch.Size([709])\n",
            "Epoch 1/100, Loss: 0.7441276907920837\n",
            "Epoch 11/100, Loss: 0.6702899932861328\n",
            "Epoch 21/100, Loss: 0.6484308838844299\n",
            "Epoch 31/100, Loss: 0.6307220458984375\n",
            "Epoch 41/100, Loss: 0.6108115315437317\n",
            "Epoch 51/100, Loss: 0.5751252174377441\n",
            "Epoch 61/100, Loss: 0.5162976384162903\n",
            "Epoch 71/100, Loss: 0.4560319185256958\n",
            "Epoch 81/100, Loss: 0.3949965834617615\n",
            "Epoch 91/100, Loss: 0.334001749753952\n",
            "torch.Size([1532, 256])\n",
            "torch.Size([1532, 3])\n",
            "\n",
            "Results for class 0 -\n",
            "Accuracy: 0.66\n",
            "F1 Score: 0.70\n",
            "Precision: 0.81\n",
            "Recall: 0.62\n",
            "\n",
            "Results for class 1 -\n",
            "Accuracy: 0.46\n",
            "F1 Score: 0.60\n",
            "Precision: 0.93\n",
            "Recall: 0.44\n",
            "\n",
            "Results for class 2 -\n",
            "Accuracy: 0.42\n",
            "F1 Score: 0.57\n",
            "Precision: 0.94\n",
            "Recall: 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4"
      ],
      "metadata": {
        "id": "zV8eJcNNqkfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/train_embeddings/+priv_train_file_{i}.json', 'r') as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            embeddings.append(data['embeddings'][0])\n",
        "            labels.append(data['label'])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.add_network()\n",
        "model.train(2, embeddings=embeddings0, labels=labels0)\n",
        "\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/dos_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([data['label'], 1, 1, 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/+info_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, data['label'], 1, 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/bypass_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, 1, data['label'], 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/+priv_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, 1, 1, data['label']])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.test(embeddings0, labels0.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBn2VssZqkqg",
        "outputId": "23e62cef-14c2-49cf-83c8-a13868ce589b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([638, 256])\n",
            "torch.Size([638])\n",
            "Epoch 1/100, Loss: 0.8878297209739685\n",
            "Epoch 11/100, Loss: 0.6105435490608215\n",
            "Epoch 21/100, Loss: 0.5229743719100952\n",
            "Epoch 31/100, Loss: 0.4826395511627197\n",
            "Epoch 41/100, Loss: 0.44857582449913025\n",
            "Epoch 51/100, Loss: 0.4127260446548462\n",
            "Epoch 61/100, Loss: 0.37526941299438477\n",
            "Epoch 71/100, Loss: 0.334656298160553\n",
            "Epoch 81/100, Loss: 0.28982973098754883\n",
            "Epoch 91/100, Loss: 0.24226541817188263\n",
            "torch.Size([1692, 256])\n",
            "torch.Size([1692, 4])\n",
            "\n",
            "Results for class 0 -\n",
            "Accuracy: 0.64\n",
            "F1 Score: 0.70\n",
            "Precision: 0.83\n",
            "Recall: 0.60\n",
            "\n",
            "Results for class 1 -\n",
            "Accuracy: 0.46\n",
            "F1 Score: 0.60\n",
            "Precision: 0.94\n",
            "Recall: 0.44\n",
            "\n",
            "Results for class 2 -\n",
            "Accuracy: 0.33\n",
            "F1 Score: 0.46\n",
            "Precision: 0.96\n",
            "Recall: 0.30\n",
            "\n",
            "Results for class 3 -\n",
            "Accuracy: 0.34\n",
            "F1 Score: 0.48\n",
            "Precision: 0.97\n",
            "Recall: 0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5"
      ],
      "metadata": {
        "id": "XDZoSdbiqk1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/train_embeddings/other_train_file_{i}.json', 'r') as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            embeddings.append(data['embeddings'][0])\n",
        "            labels.append(data['label'])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.add_network()\n",
        "model.train(2, embeddings=embeddings0, labels=labels0)\n",
        "\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/dos_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([data['label'], 1, 1, 1, 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/+info_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, data['label'], 1, 1, 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/bypass_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, 1, data['label'], 1, 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/+priv_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, 1, 1, data['label'], 1])\n",
        "\n",
        "with open(f'/content/drive/MyDrive/CSCI544-Project/data/class_wise_embeddings/test_embeddings/other_test_file.json', 'r') as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        embeddings.append(data['embeddings'][0])\n",
        "        labels.append([1, 1, 1, 1, data['label']])\n",
        "\n",
        "# Convert lists to tensors\n",
        "embeddings0 = torch.tensor(embeddings)\n",
        "labels0 = torch.tensor(labels)\n",
        "\n",
        "print(embeddings0.size())  # This will show the shape of the embeddings tensor\n",
        "print(labels0.size())     # This will show the shape of the labels tensor\n",
        "\n",
        "model.test(embeddings0, labels0.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXVl6YCrqlAy",
        "outputId": "1598aed2-4bae-46eb-9e76-ef9ff4551dc3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([800, 256])\n",
            "torch.Size([800])\n",
            "Epoch 1/100, Loss: 1.2902934551239014\n",
            "Epoch 11/100, Loss: 0.5481863617897034\n",
            "Epoch 21/100, Loss: 0.3996991813182831\n",
            "Epoch 31/100, Loss: 0.33156898617744446\n",
            "Epoch 41/100, Loss: 0.2819080948829651\n",
            "Epoch 51/100, Loss: 0.2394256442785263\n",
            "Epoch 61/100, Loss: 0.20193754136562347\n",
            "Epoch 71/100, Loss: 0.16852302849292755\n",
            "Epoch 81/100, Loss: 0.13897638022899628\n",
            "Epoch 91/100, Loss: 0.11328723281621933\n",
            "torch.Size([1892, 256])\n",
            "torch.Size([1892, 5])\n",
            "\n",
            "Results for class 0 -\n",
            "Accuracy: 0.65\n",
            "F1 Score: 0.72\n",
            "Precision: 0.85\n",
            "Recall: 0.62\n",
            "\n",
            "Results for class 1 -\n",
            "Accuracy: 0.48\n",
            "F1 Score: 0.63\n",
            "Precision: 0.95\n",
            "Recall: 0.47\n",
            "\n",
            "Results for class 2 -\n",
            "Accuracy: 0.78\n",
            "F1 Score: 0.88\n",
            "Precision: 0.95\n",
            "Recall: 0.82\n",
            "\n",
            "Results for class 3 -\n",
            "Accuracy: 0.33\n",
            "F1 Score: 0.47\n",
            "Precision: 0.98\n",
            "Recall: 0.31\n",
            "\n",
            "Results for class 4 -\n",
            "Accuracy: 0.34\n",
            "F1 Score: 0.47\n",
            "Precision: 0.99\n",
            "Recall: 0.31\n"
          ]
        }
      ]
    }
  ]
}